model_path = "C:/Users/Acer/Downloads/roseeai/deepseek-7b"

from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    local_files_only=True,
    torch_dtype=torch.float32  # Use float32 for low RAM systems
    # Remove device_map if no GPU
)
